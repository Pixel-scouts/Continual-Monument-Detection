{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.datasets import MonumentsDataset\n",
    "from models import datasets\n",
    "from models.utils import get_train_transform, collate_fn\n",
    "from models import fasterrcnn\n",
    "from datasets import class_list\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasterrcnn.fasterrcnn_resnet50_fpn(num_classes=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0543581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model_path=\"E:\\Major Project\\Continual-Monument-Detection\\models\\saved\\model10 (1).pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "# weights=torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd84e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d808f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "clases=['kiranteshwor mahadev', 'charumati', 'kumaristhan', 'ume_maheshwara', 'jaya bageshwori', 'birupakshya', 'Naxal Bhagwati', 'Krishna_temple _kobahal', 'chakku bakku', 'golden temple', 'Ram Mandir', 'uma maheshwor', 'Maitidevi Temple', 'guyeshwori', 'nagarmandap shree kriti bihar', 'Jalbinayak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4106bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"E:\\Major Project\\Continual-Monument-Detection\\dataset\"\n",
    "dataset = MonumentsDataset(TRAIN_DIR, 512, 512, clases, get_train_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "print(len(indices))\n",
    "print(indices[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08e9111",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.Subset(dataset, indices[:-500])\n",
    "eval_set=torch.utils.data.Subset(dataset, indices[-500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7617a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336037bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(\n",
    "    eval_set,\n",
    "    batch_size=5,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "predictions=[{'boxes': tensor([[ 84.1036,  76.5165, 271.7503, 443.8830],[ 84.1036,  76.5165, 271.7503, 443.8830],\n",
    "                    [ 84.1036,  76.5165, 271.7503, 443.8830],\n",
    "                    [ 84.1036,  76.5165, 271.7503, 443.8830],]), \n",
    "              'labels': tensor([1, 1, 4,6]),\n",
    "              'scores': tensor([0.9965,0.8, 0.2779, 0.0586])},\n",
    "             {'boxes': tensor([[239.2319, 219.7705, 343.4445, 404.7963]]),\n",
    "              'labels': tensor([5]),\n",
    "              'scores': tensor([0.9982])},\n",
    "             {'boxes': tensor([[ 77.5203,  86.0100, 506.1534, 484.8054]]),\n",
    "              'labels': tensor([12]),\n",
    "              'scores': tensor([0.9954])},\n",
    "             {'boxes': tensor([[134.1839, 174.5545, 394.9434, 375.4676],\n",
    "                               [106.7353, 121.3933, 373.4354, 412.4706]]),\n",
    "              'labels': tensor([8, 2]),\n",
    "              'scores': tensor([0.9917, 0.0847])},\n",
    "             {'boxes': tensor([[106.1037,  84.3046, 465.6261, 400.9447],\n",
    "                               [146.9601, 165.3507, 469.2495, 417.4515],\n",
    "                               [ 61.8506,  23.7119, 470.3089, 432.0762],\n",
    "                               [ 86.0900,  59.0844, 436.2623, 460.5981],\n",
    "                               [134.8938,  92.4572, 458.3427, 414.5243],\n",
    "                               [ 36.1431,  89.5182, 480.6086, 381.3042],\n",
    "                               [140.2368, 103.6454, 453.7489, 434.0392]]),\n",
    "              'labels': tensor([ 3,  8,  4, 12,  6,  8,  7]),\n",
    "              'scores': tensor([0.8088, 0.4658, 0.2955, 0.2125, 0.1203, 0.0985, 0.0970])}]\n",
    "\n",
    "targets=[{'boxes': tensor([[ 84.1036,  76.5165, 271.7503, 443.8830],\n",
    "                    ]), \n",
    "              'labels': tensor([1, ]),\n",
    "              'scores': tensor([0.9965])},\n",
    "             {'boxes': tensor([[239.2319, 219.7705, 343.4445, 404.7963]]),\n",
    "              'labels': tensor([5]),\n",
    "              'scores': tensor([0.9982])},\n",
    "             {'boxes': tensor([[ 77.5203,  86.0100, 506.1534, 484.8054]]),\n",
    "              'labels': tensor([8]),\n",
    "              'scores': tensor([0.9954])},\n",
    "             {'boxes': tensor([[134.1839, 174.5545, 394.9434, 375.4676]]),\n",
    "              'labels': tensor([8]),\n",
    "              'scores': tensor([0.9917])},\n",
    "             {'boxes': tensor([[106.1037,  84.3046, 465.6261, 400.9447]\n",
    "                              ]),\n",
    "              'labels': tensor([3]),\n",
    "              'scores': tensor([0.8088])}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd7f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_preds(predicted,threshold=0.6):\n",
    "    filtered_predictions = []\n",
    "    scores = []\n",
    "\n",
    "    for pred in predicted:\n",
    "        scores = pred['scores']\n",
    "        indices = scores > threshold\n",
    "        if indices.any():\n",
    "            filtered_boxes = pred['boxes'][indices]\n",
    "            filtered_labels = pred['labels'][indices]\n",
    "            filtered_scores = pred['scores'][indices]\n",
    "            filtered_pred = {'boxes': filtered_boxes,\n",
    "                             'labels': filtered_labels,\n",
    "                             'scores': filtered_scores}\n",
    "        else:\n",
    "            filtered_boxes = torch.tensor([[0, 0, 0, 0]])\n",
    "            filtered_labels = torch.tensor([0])\n",
    "            filtered_scores =torch.tensor([1])\n",
    "            filtered_pred = {'boxes': filtered_boxes,\n",
    "                             'labels': filtered_labels,\n",
    "                             'scores': filtered_scores}\n",
    "        filtered_predictions.append(filtered_pred)\n",
    "    return filtered_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07954118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import tensor\n",
    "def sort_predictions(predictions,targets,threshold=0.6):\n",
    "    target_labels=[]\n",
    "    pred_labels=[]\n",
    "    pred_scores=[]\n",
    "    for target,prediction in zip(targets,predictions):\n",
    "        for i, box in enumerate(prediction['boxes']):\n",
    "            match=0\n",
    "            for j, pbox in enumerate(target['boxes']):\n",
    "                intersection=(min(box[2],pbox[2])-max(box[0],pbox[0]))*(min(box[3],pbox[3])-max(box[1],pbox[1]))\n",
    "                union=(box[2]-box[0])*(box[3]-box[1])+ (pbox[2]-pbox[0])*(pbox[3]-pbox[1])-intersection\n",
    "                iou=intersection/union\n",
    "                if (iou>0.6):\n",
    "                    match+=1\n",
    "                    label=target['labels'][j]\n",
    "                    output=prediction['labels'][i]\n",
    "                    score=prediction['scores'][i]\n",
    "                    target_labels.append(label)\n",
    "                    pred_scores.append(score)\n",
    "                    pred_labels.append(output)\n",
    "            if (match==0):\n",
    "                label=tensor(0)\n",
    "                output=prediction['labels'][i]\n",
    "                score=prediction['scores'][i]\n",
    "                target_labels.append(label)\n",
    "                pred_scores.append(score)\n",
    "                pred_labels.append(output)\n",
    "        for i, box in enumerate(target['boxes']):\n",
    "            match=0\n",
    "            for j, pbox in enumerate(prediction['boxes']):\n",
    "                intersection=(min(box[2],pbox[2])-max(box[0],pbox[0]))*(min(box[3],pbox[3])-max(box[1],pbox[1]))\n",
    "                union=(box[2]-box[0])*(box[3]-box[1])+ (pbox[2]-pbox[0])*(pbox[3]-pbox[1])-intersection\n",
    "                iou=intersection/union\n",
    "                if (iou>0.6):\n",
    "                    match+=1\n",
    "            if (match==0):\n",
    "                output=tensor(0)\n",
    "                score=tensor(1)\n",
    "                label=target['labels'][i]\n",
    "                pred_scores.append(score)\n",
    "                target_labels.append(label)\n",
    "                pred_labels.append(output)\n",
    "    return target_labels,pred_labels,pred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3415651",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_predictions=filter_preds(predictions,0.6)\n",
    "target_labels, pred_labels,_=sort_predictions(filtered_predictions,targets,0.6)                \n",
    "conf_matrix = confusion_matrix(target_labels, pred_labels)\n",
    "print(target_labels)\n",
    "print(pred_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccfacd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate classification report for the predictions\n",
    "from sklearn.metrics import classification_report\n",
    "report=classification_report(target_labels,pred_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original=[]\n",
    "predicted=[]\n",
    "imgs=0\n",
    "with torch.no_grad():\n",
    "    for batch in valid_loader:\n",
    "        images, targets = batch\n",
    "        images = list(image.to(DEVICE) for image in images)\n",
    "        imgs+=len(images)\n",
    "        target = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]  \n",
    "        original.extend(target)\n",
    "        predictions = model(images)\n",
    "        predicted.extend(predictions)\n",
    "print(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e6032",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filtered_predictions=filter_preds(predicted,0.6)\n",
    "target_labels, pred_labels,pred_scores = sort_predictions(filtered_predictions,original,0.6)                \n",
    "conf_matrix = confusion_matrix(target_labels, pred_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8b65c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,xticklabels=clases, yticklabels=clases)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=None, bbox_inches='tight', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ff50f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "report=classification_report(target_labels,pred_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a5f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_PR(report):\n",
    "    class_report_lines = report.split('\\n')[2:-3]  # Exclude header and footer lines\n",
    "    class_precision = {}\n",
    "    class_recall = {}\n",
    "    class_support = {}\n",
    "    for line in class_report_lines:\n",
    "        class_info = line.strip().split()\n",
    "        if(len(class_info)==0):\n",
    "            continue\n",
    "        class_name = class_info[0]\n",
    "        class_precision[class_name] = float(class_info[1])\n",
    "        class_recall[class_name] = float(class_info[2])\n",
    "        class_support[class_name] = int(class_info[-1])\n",
    "\n",
    "def avg_PR(report):\n",
    "    avg_report=report.split('\\n')[-4:]\n",
    "    for line in avg_report:\n",
    "        class_info = line.strip().split()\n",
    "        class_name = class_info[0]\n",
    "        if (class_name=='weighted'):\n",
    "            precision=class_info[2]\n",
    "            recall=class_info[3]\n",
    "            print(precision,recall)\n",
    "            return precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PR_list(original,predicted):\n",
    "    precisions=[]\n",
    "    recalls=[]\n",
    "    threshold=0\n",
    "    precision=0\n",
    "    recall=0\n",
    "    while threshold<=1.0:\n",
    "        filtered_predictions=filter_preds(predicted,threshold)\n",
    "        target_labels, pred_labels,_=sort_predictions(filtered_predictions,original,0.6) \n",
    "        report=classification_report(target_labels,pred_labels)\n",
    "        precision,recall=avg_PR(report)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        threshold+=0.025\n",
    "    return precisions,recalls\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions,recalls=PR_list(original,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions.reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25afd559",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precisions)\n",
    "print(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b613fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth interpolation for continuous curv\n",
    "\n",
    "precision = [float(p) for p in precisions]\n",
    "recall = [float(r) for r in recalls]\n",
    "\n",
    "# Plot the PR curve\n",
    "plt.plot(recall, precision, linestyle='-')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(True)\n",
    "\n",
    "# Set x-axis and y-axis limits to 0 and 1\n",
    "# plt.xlim(0, 1)\n",
    "# plt.ylim(0, 1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b864f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_box(targets):\n",
    "    count=0\n",
    "    for target in targets:\n",
    "        for box in target['boxes']:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_box(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7609da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "# Assuming you have the following:\n",
    "# pred_labels: Predicted class labels\n",
    "# pred_scores: Predicted confidence scores\n",
    "# target_labels: Ground truth class labels (correct labels)\n",
    "# threshold_range: List of confidence score thresholds\n",
    "\n",
    "# Create an empty list to store the precision and recall values\n",
    "precisions = []\n",
    "recalls = []\n",
    "count=count_box(original)\n",
    "# Loop through each threshold in the threshold range\n",
    "threshold=0\n",
    "while threshold<=1:\n",
    "    filtered_predictions=filter_preds(predictions,threshold)\n",
    "    target_labels, pred_labels,pred_scores = sort_predictions(predicted,original,0.6) \n",
    "    # Filter predictions based on the current threshold\n",
    "    filtered_indices = [i for i, score in enumerate(pred_scores) if score > threshold]\n",
    "    filtered_pred_labels = [pred_labels[i] for i in filtered_indices]\n",
    "    \n",
    "    # Compute true positive, false positive, and false negative detections\n",
    "    true_positives = np.sum(np.in1d(filtered_pred_labels, target_labels))\n",
    "    false_positives = len(filtered_pred_labels) - true_positives\n",
    "    false_negatives = np.sum(np.in1d(target_labels, filtered_pred_labels, invert=True))\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / count\n",
    "    \n",
    "    # Append precision and recall to the lists\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    threshold+=0.01\n",
    "\n",
    "# Plot the PR curve\n",
    "plt.plot(recalls, precisions, marker='o', linestyle='-')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c80618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Assuming 'original' is a list of dictionaries where each dictionary contains the 'image' tensor and 'boxes' tensor for the ground truth bounding boxes\n",
    "# Assuming 'predicted' is a list of dictionaries where each dictionary contains the 'image' tensor and 'boxes' tensor for the predicted bounding boxes\n",
    "\n",
    "# Convert the 'image' tensors and 'boxes' tensors from the dictionaries to NumPy arrays\n",
    "images_cpu = [image.cpu() for image in photos]\n",
    "\n",
    "# Convert the CPU tensors to NumPy arrays\n",
    "original_np = [image.numpy() for image in images_cpu]\n",
    "predicted_np = original_np\n",
    "predicted_label=[item['labels'].cpu().numpy() for item in filtered_predictions]\n",
    "# original_np = [item['image'].cpu().numpy() for item in original]\n",
    "original_boxes = [item['boxes'].cpu().numpy() for item in original]\n",
    "# predicted_np = [item['image'].cpu().numpy() for item in predicted]\n",
    "predicted_boxes = [item['boxes'].cpu().numpy() for item in filtered_predictions]\n",
    "\n",
    "# Visualize the original and predicted images with bounding boxes\n",
    "fig, axs = plt.subplots(len(original), 2, figsize=(10, 5 * len(original)))\n",
    "\n",
    "for i in range(len(original)):\n",
    "    image_bgr = original_np[i].transpose(1,2,0)[:, :, ::-1]\n",
    "    # Original Image\n",
    "    axs[i, 0].imshow(image_bgr)  # Assuming original images are in CHW format\n",
    "    axs[i, 0].axis('off')\n",
    "    axs[i, 0].set_title('Original')\n",
    "\n",
    "    # Predicted Image with Bounding Boxes\n",
    "    axs[i, 1].imshow(image_bgr)  # Assuming predicted images are in CHW format\n",
    "    axs[i, 1].axis('off')\n",
    "    axs[i, 1].set_title('Predicted')\n",
    "\n",
    "    # Add ground truth bounding boxes to the original image\n",
    "    for box in original_boxes[i]:\n",
    "        rect = patches.Rectangle(\n",
    "            (box[0], box[1]), box[2] - box[0], box[3] - box[1], linewidth=2, edgecolor='r', facecolor='none'\n",
    "        )\n",
    "        axs[i, 0].add_patch(rect)\n",
    "#         axs[i,0].text(\n",
    "#             box[0], box[1] - 5, f'{clases[int(predicted_label[i])-1]}', color='r', fontsize=10,\n",
    "#             bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', boxstyle='round,pad=0.2')\n",
    "#         )\n",
    "        axs[i, 0].add_patch(rect)\n",
    "        axs[i,0].text(\n",
    "            box[0], box[1] - 5, f'jal binayak', color='r', fontsize=10,\n",
    "            bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', boxstyle='round,pad=0.2')\n",
    "        )\n",
    "\n",
    "\n",
    "    # Add predicted bounding boxes to the predicted image\n",
    "    for box in predicted_boxes[i]:\n",
    "        rect = patches.Rectangle(\n",
    "            (box[0], box[1]), box[2] - box[0], box[3] - box[1], linewidth=2, edgecolor='g', facecolor='none'\n",
    "        )\n",
    "#         axs[i, 1].add_patch(rect)\n",
    "#         axs[i,1].text(\n",
    "#             box[0], box[1] - 5, f'{clases[int(predicted_label[i])-1]}', color='r', fontsize=10,\n",
    "#             bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', boxstyle='round,pad=0.2')\n",
    "#         )\n",
    "        axs[i, 1].add_patch(rect)\n",
    "        axs[i,1].text(\n",
    "            box[0], box[1] - 5, f'kiranteswor mahadev', color='r', fontsize=10,\n",
    "            bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', boxstyle='round,pad=0.2')\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e88e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
